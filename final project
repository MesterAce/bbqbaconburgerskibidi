import os
import requests
import json
import csv
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Links and API key
UNSPLASH_URL = "https://api.unsplash.com"
UNSPLASH_KEY = "e7B8RzVvvok2XZeyfXMBuX9Nove9Z3r98tCS-8Qv7xQ"
PHOTOTAG_API_KEY = "0MdP-xt7m-5pOq-kbfM-NAdt-sD1"
PHOTOTAG_URL = "https://server.phototag.ai/api/keywords"
IMG_NUM = 10
SAVE_ROOT = "images"

def fetch_images():
    headers = {"Authorization": f"Client-ID {UNSPLASH_KEY}"}
    params = {"count": IMG_NUM}
    response = requests.get(f"{UNSPLASH_URL}/photos/random", headers=headers, params=params)
    return response.json()

def download_image(image_data, save_dir):
    img_url = image_data["urls"]["regular"]
    response = requests.get(img_url, stream=True)
    img_path = os.path.join(save_dir, "image.jpg")
    with open(img_path, "wb") as file:
        for chunk in response.iter_content(1024):
            file.write(chunk)
    return img_path

def enhance_metadata(img_path):
    headers = {"Authorization": f"Bearer {PHOTOTAG_API_KEY}"}
    payload = {
        "language": "en",
        "maxKeywords": 5,
        "requiredKeywords": "beach,sky",
        "customContext": "vacation photo"
    }
    files = [('file', open(img_path, 'rb'))]
    response = requests.post(PHOTOTAG_URL, headers=headers, data=payload, files=files)
    return response.json()

def store_metadata(image_data, enhanced_metadata, save_dir):
    metadata = {
        "original": {
            "id": image_data["id"],
            "photographer": image_data["user"]["name"],
            "description": image_data.get("description", ""),
            "alt_description": image_data.get("alt_description", ""),
            "urls": image_data["urls"]
        },
        "enhanced": enhanced_metadata
    }
    json_filename = os.path.join(save_dir, "metadata.json")
    with open(json_filename, "w") as json_file:
        json.dump(metadata, json_file, indent=4)

def process_image(image_data, idx):
    save_dir = os.path.join(SAVE_ROOT, f"image_{idx + 1}")
    os.makedirs(save_dir, exist_ok=True)
    img_path = download_image(image_data, save_dir)
    enhanced_metadata = enhance_metadata(img_path)
    store_metadata(image_data, enhanced_metadata, save_dir)
    return {
        "id": f"image_{idx + 1}",
        "photographer": image_data["user"]["name"],
        "enhanced": enhanced_metadata
    }
     # csv file 
def create_csv(images_data):
    summary_filepath = os.path.join(SAVE_ROOT, "summary.csv")
    with open(summary_filepath, "w", newline='') as csvfile:
        fieldnames = ["image_id", "photographer", "enhanced_title", "enhanced_description", "enhanced_tags"]
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for img_data in images_data:
            writer.writerow({
                "image_id": img_data["id"],
                "photographer": img_data["photographer"],
                "enhanced_title": img_data["enhanced"].get("title", ""),
                "enhanced_description": img_data["enhanced"].get("description", ""),
                "enhanced_tags": ",".join(img_data["enhanced"].get("tags", []))
            })

def main():
    os.makedirs(SAVE_ROOT, exist_ok=True)
    images_data = fetch_images()
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(process_image, image_data, idx) for idx, image_data in enumerate(images_data)]
        all_images_data = [future.result() for future in as_completed(futures)]
    create_csv(all_images_data)

if __name__ == "__main__":
    main()
